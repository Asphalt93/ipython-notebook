{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류 기본모형\n",
    "## Iris Data를 이용한 베이즈 추론 \n",
    "\n",
    "널리 알려진 데이터인 Iris를 활용해서 베이즈 추론을 해볼 것이다. Iris 데이터는 꽃잎과 꽃받침의 길이/넓이를 통해서 개화되는 꽃의 종류(setosa,versicolor,virginica)를 예측한다. 우선 Train Set에서 다음과 같은 결과 값이 나왔다고 \n",
    "\n",
    "|             | setosa | versicolor|virginica |\n",
    "| :------ :   |:------:| :------:  | :------: |\n",
    "| Sampe 결과   | 2      |      3     |      5    |\n",
    "\n",
    "베이즈 정리를 통해서 $X_n $사건이후 setosa꽃이 필 조건부 확률 P($setosa\\mid x_n$)는 아래과 같은 수식으로 표현될 수 있다. 여기서 P(setosa)는 쉽게 구할 수 있다. 2/(2+3+5)=0.2이다.\n",
    "\n",
    "$$P(Seotsa \\mid x_n )=\\frac{P(setosa)P( x_n \\mid setosa)}{P(setosa)P( x_n \\mid setosa)+P(versicolor)P( x_n \\mid versicolor)+P(virginica)P( x_n \\mid virginica) } $$ \n",
    "\n",
    "\n",
    "그렇다면 $P(x_n \\mid setosa)$는 어떻게 구할까? setosa,versicolor,virginica 마다 각각의 확률분포를 가진다. Naive Bayes에서는 이 확률 분포에 대해서 정의를 먼저 해야한다. 본 글에서는 각 데이터를의 정규분포를 가정해서 베이즈 주의 추론을 해보겠다. \n",
    "\n",
    "|             | setosa        | versicolor|virginica |\n",
    "| :-------- : |:-----------:  | :-----:   | :-----:  |\n",
    "| Sepal.Length|$ N(\\mu,\\sigma)$|          |          |\n",
    "| Sepal.Width |               |           |          |\n",
    "| Petal.Length|               |           |          |\n",
    "| Petal.Width |             |           |          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b4959d0790b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sepal_length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sepal_width'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'petal_length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'petal_width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df= pd.DataFrame(iris.data, columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "df_output= pd.Series(iris.target,dtype=\"category\")\n",
    "df_output= df_output.cat.rename_categories(iris.target_names)\n",
    "df['species']=df_output\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure();\n",
    "ax1 = fig.add_subplot(4, 3, 1);ax1.hist(df[df['species']=='setosa']['sepal_length'],color='red')\n",
    "ax2 = fig.add_subplot(4, 3, 2);ax2.hist(df[df['species']=='versicolor']['sepal_length'],color='red')\n",
    "ax3 = fig.add_subplot(4, 3, 3);ax3.hist(df[df['species']=='virginica']['sepal_length'],color='red')\n",
    "\n",
    "ax4 = fig.add_subplot(4, 3, 4);ax4.hist(df[df['species']=='setosa']['sepal_width'])\n",
    "ax5 = fig.add_subplot(4, 3, 5);ax5.hist(df[df['species']=='versicolor']['sepal_width'])\n",
    "ax6 = fig.add_subplot(4, 3, 6);ax6.hist(df[df['species']=='virginica']['sepal_width'])\n",
    "\n",
    "ax7 = fig.add_subplot(4, 3, 7);ax7.hist(df[df['species']=='setosa']['petal_length'],color='green')\n",
    "ax8 = fig.add_subplot(4, 3, 8);ax8.hist(df[df['species']=='versicolor']['petal_length'],color='green')\n",
    "ax9 = fig.add_subplot(4, 3, 9);ax9.hist(df[df['species']=='virginica']['petal_length'],color='green')\n",
    "\n",
    "ax10 = fig.add_subplot(4, 3, 10);ax10.hist(df[df['species']=='setosa']['petal_width'],color='purple')\n",
    "ax11 = fig.add_subplot(4, 3, 11);ax11.hist(df[df['species']=='versicolor']['petal_width'],color='purple')\n",
    "ax12 = fig.add_subplot(4, 3, 12);ax12.hist(df[df['species']=='virginica']['petal_width'],color='purple')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 해당 분포정규분포를 이루기에는 충분하지는 않지만, 연습이니 만큼 정규분포를 가정하고 추론을 진행하겠다. 본 Iris에서는 $ P(Sepal.Length \\mid setosa) \\cdots $ 등 총 12개의 조건부 확률 기반한 정규분포를 가진다. 각각이 정규분포의 평균과 분산을 가진다. 만약에서 새로운 사건 $x_n$ 에서 값이 (1,2,3,4)가 나았다고 가정 해보자. 조건부 확률은 아래과 같이 표시될 수 있다.  \n",
    "\n",
    "* $P(Sepal.Length=1\\mid Setosa) = P(\\frac{1-\\mu_{setosa}}{\\sigma_{setosa}})$\n",
    "* $P(Sepal.Width=2\\mid Setosa) = P(\\frac{2-\\mu_{setosa}}{\\sigma_{setosa}})$\n",
    "* $P(Petal.Length=3\\mid Setosa) = P(\\frac{3-\\mu_{setosa}}{\\sigma_{setosa}})$\n",
    "* $P(Petal.Width=4\\mid Setosa) = P(\\frac{4-\\mu_{setosa}}{\\sigma_{setosa}})$\n",
    "\n",
    "사건 $x_n$이 일어났을때, 그것이 Setosa일 조건부확률은 아래와 같고,versicolor,virginica일 경우도 이와 비슷하게 예측을 하면 된다. \n",
    "\n",
    "$$P( x_n \\mid setosa)=P(Setosa)P(Sepal.Length=1\\mid Setosa)+P(Setosa)P(Sepal.Width=2\\mid Setosa)+P(Setosa)P(Petal.Length=3\\mid Setosa)+ P(Setosa)P(Petal.Width=4\\mid Setosa)$$ \n",
    "\n",
    "이런 방식으로 $P(setosa\\mid x_n)$,$P(versicolor\\mid x_n)$,$P(virginica \\mid x_n)$의 확률을 구할 수 있고 가장 높은 조건부 확률로 $x_n$를 분류하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'예측값과 실제값의 불일치': 0, '예측값과 실제값의 일치': 38}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y=df['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=42)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "compare=pd.DataFrame({\"예측\":y_pred,\"실제\":y_test})\n",
    "{'예측값과 실제값의 일치':sum(compare['실제']==compare['예측']),'예측값과 실제값의 불일치':sum(compare['실제'] != compare['예측'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes 분류를 통해서, 모든 셀에서 예측을 성공했다. 사실 이번 예측은 운이 좋은 예측이고 보다 좋은 예측을 위해서는 확률분포를 보다 엄밀하게 정의할 필요가 있다. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
